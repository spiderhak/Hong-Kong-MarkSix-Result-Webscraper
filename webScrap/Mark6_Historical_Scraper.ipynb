{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# STEP 1: IMPORT LIBRARIES AND SETUP\n",
        "# =============================================================================\n",
        "# Import necessary libraries for web scraping and data processing\n",
        "import pandas as pd  # For data manipulation and analysis\n",
        "import ssl           # For handling SSL certificates\n",
        "import warnings      # For suppressing warnings\n",
        "import time          # For adding delays between requests\n",
        "from datetime import datetime  # For date handling\n",
        "\n",
        "# Suppress warnings to keep output clean\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Handle SSL certificate issues (needed for some websites)\n",
        "# This allows us to access HTTPS websites without certificate verification\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully!\")\n",
        "print(\"üìö Ready to start historical web scraping (1993-2025)...\")\n",
        "print(f\"üïê Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# STEP 2: DEFINE DATA CLEANING FUNCTIONS\n",
        "# =============================================================================\n",
        "\n",
        "def clean_lottery_data(df, year):\n",
        "    \"\"\"\n",
        "    Clean the lottery data by removing monthly header rows and invalid data\n",
        "    \n",
        "    Parameters:\n",
        "    df (DataFrame): Raw lottery data from web scraping\n",
        "    year (int): Year being processed (for logging)\n",
        "    \n",
        "    Returns:\n",
        "    DataFrame: Cleaned data with monthly headers removed\n",
        "    \"\"\"\n",
        "    print(f\"üìä {year} - Original data shape: {df.shape}\")\n",
        "    \n",
        "    # Create a copy to avoid modifying the original data\n",
        "    df_clean = df.copy()\n",
        "    \n",
        "    # Find and remove monthly header rows (e.g., \"September 2025\", \"August 2025\")\n",
        "    monthly_rows = []\n",
        "    for idx, row in df_clean.iterrows():\n",
        "        # Get all non-null values in the row\n",
        "        non_null_values = [str(val) for val in row if pd.notna(val)]\n",
        "        \n",
        "        if len(non_null_values) > 0:\n",
        "            # Check if all values are the same and contain month names\n",
        "            # This identifies rows like \"September 2025, September 2025, September 2025\"\n",
        "            if len(set(non_null_values)) == 1 and any(month in non_null_values[0] for month in \n",
        "                ['January', 'February', 'March', 'April', 'May', 'June', \n",
        "                 'July', 'August', 'September', 'October', 'November', 'December']):\n",
        "                monthly_rows.append(idx)\n",
        "    \n",
        "    # Remove the identified monthly header rows\n",
        "    df_clean = df_clean.drop(monthly_rows)\n",
        "    \n",
        "    # Remove rows where Draw Number doesn't contain a slash (invalid lottery numbers)\n",
        "    # Valid lottery numbers should look like \"25/096\", \"25/095\", etc.\n",
        "    if 'Draw Number' in df_clean.columns:\n",
        "        df_clean = df_clean[df_clean['Draw Number'].str.contains('/', na=False)]\n",
        "    \n",
        "    # Reset the index after dropping rows (important for data integrity)\n",
        "    df_clean = df_clean.reset_index(drop=True)\n",
        "    \n",
        "    print(f\"üóëÔ∏è  {year} - Removed {len(monthly_rows)} monthly header rows\")\n",
        "    print(f\"üìä {year} - Cleaned data shape: {df_clean.shape}\")\n",
        "    \n",
        "    return df_clean\n",
        "\n",
        "def split_balls_drawn(balls_str):\n",
        "    \"\"\"\n",
        "    Split balls drawn string into individual numbers\n",
        "    \n",
        "    Parameters:\n",
        "    balls_str (str): String containing lottery numbers (e.g., \"5 18 23 24 29 49 11\")\n",
        "    \n",
        "    Returns:\n",
        "    list: List of 7 individual numbers\n",
        "    \"\"\"\n",
        "    # Handle missing values\n",
        "    if pd.isna(balls_str):\n",
        "        return [None] * 7\n",
        "    \n",
        "    # Remove commas and split by spaces, then filter out empty strings\n",
        "    numbers = [num.strip() for num in str(balls_str).replace(',', '').split() if num.strip()]\n",
        "    \n",
        "    # Ensure we have exactly 7 numbers (pad with None if less)\n",
        "    while len(numbers) < 7:\n",
        "        numbers.append(None)\n",
        "    \n",
        "    # Return only the first 7 numbers (in case there are more)\n",
        "    return numbers[:7]\n",
        "\n",
        "def process_lottery_data(df, year):\n",
        "    \"\"\"\n",
        "    Process lottery data for a specific year\n",
        "    \n",
        "    Parameters:\n",
        "    df (DataFrame): Raw lottery data\n",
        "    year (int): Year being processed\n",
        "    \n",
        "    Returns:\n",
        "    DataFrame: Processed data ready for analysis\n",
        "    \"\"\"\n",
        "    if df is None or df.empty:\n",
        "        print(f\"‚ùå {year} - No data available\")\n",
        "        return None\n",
        "    \n",
        "    # Clean the data\n",
        "    df_clean = clean_lottery_data(df, year)\n",
        "    \n",
        "    if df_clean.empty:\n",
        "        print(f\"‚ùå {year} - No valid data after cleaning\")\n",
        "        return None\n",
        "    \n",
        "    # Drop unnecessary columns if they exist\n",
        "    columns_to_drop = ['Draw Number', 'Details']\n",
        "    existing_columns_to_drop = [col for col in columns_to_drop if col in df_clean.columns]\n",
        "    if existing_columns_to_drop:\n",
        "        df_clean = df_clean.drop(columns=existing_columns_to_drop)\n",
        "        print(f\"üóëÔ∏è  {year} - Removed columns: {existing_columns_to_drop}\")\n",
        "    \n",
        "    # Format balls drawn with commas\n",
        "    if 'Balls Drawn' in df_clean.columns:\n",
        "        def format_balls_drawn(balls_str):\n",
        "            if pd.isna(balls_str):\n",
        "                return balls_str\n",
        "            numbers = [num.strip() for num in str(balls_str).split() if num.strip()]\n",
        "            return ', '.join(numbers)\n",
        "        \n",
        "        df_clean['Balls Drawn'] = df_clean['Balls Drawn'].apply(format_balls_drawn)\n",
        "        \n",
        "        # Split into individual number columns\n",
        "        balls_data = df_clean['Balls Drawn'].apply(split_balls_drawn)\n",
        "        \n",
        "        for i in range(7):\n",
        "            df_clean[f'num{i+1}'] = balls_data.apply(lambda x: x[i])\n",
        "        \n",
        "        # Remove the original Balls Drawn column\n",
        "        df_clean = df_clean.drop(columns=['Balls Drawn'])\n",
        "        \n",
        "        print(f\"üî¢ {year} - Separated numbers into 7 columns\")\n",
        "    \n",
        "    # Note: Year column removed as requested - data will be identified by Draw Date only\n",
        "    \n",
        "    print(f\"‚úÖ {year} - Processing completed. Final shape: {df_clean.shape}\")\n",
        "    \n",
        "    return df_clean\n",
        "\n",
        "print(\"‚úÖ Data processing functions defined successfully!\")\n",
        "print(\"üîß Functions ready: clean_lottery_data(), split_balls_drawn(), process_lottery_data()\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# STEP 3: DEFINE YEARS TO SCRAPE AND INITIALIZE\n",
        "# =============================================================================\n",
        "\n",
        "# Define the range of years to scrape (1993 to 2025)\n",
        "start_year = 1993\n",
        "end_year = 2025\n",
        "years_to_scrape = list(range(start_year, end_year + 1))\n",
        "\n",
        "print(f\"üìÖ Years to scrape: {start_year} to {end_year}\")\n",
        "print(f\"üî¢ Total years: {len(years_to_scrape)}\")\n",
        "print(f\"üìã Years list: {years_to_scrape}\")\n",
        "\n",
        "# Initialize variables for data collection\n",
        "all_data = []  # List to store all processed data\n",
        "successful_years = []  # Track successfully scraped years\n",
        "failed_years = []  # Track failed years\n",
        "\n",
        "print(f\"\\n‚úÖ Initialization completed!\")\n",
        "print(f\"üìä Ready to scrape {len(years_to_scrape)} years of lottery data\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# STEP 4: SCRAPE DATA FOR EACH YEAR\n",
        "# =============================================================================\n",
        "\n",
        "print(\"üåê Starting historical data scraping...\")\n",
        "print(\"‚è≥ This may take several minutes due to the large amount of data...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for i, year in enumerate(years_to_scrape, 1):\n",
        "    print(f\"\\nüìÖ Processing year {year} ({i}/{len(years_to_scrape)})...\")\n",
        "    \n",
        "    try:\n",
        "        # Construct URL for the specific year\n",
        "        url = f\"https://lottery.hk/en/mark-six/results/{year}\"\n",
        "        print(f\"üåê Fetching: {url}\")\n",
        "        \n",
        "        # Scrape data for this year\n",
        "        scraped = pd.read_html(url)\n",
        "        \n",
        "        if scraped and len(scraped) > 0:\n",
        "            # Get the first table (main results table)\n",
        "            df_year = scraped[0]\n",
        "            \n",
        "            # Process the data for this year\n",
        "            processed_data = process_lottery_data(df_year, year)\n",
        "            \n",
        "            if processed_data is not None and not processed_data.empty:\n",
        "                all_data.append(processed_data)\n",
        "                successful_years.append(year)\n",
        "                print(f\"‚úÖ {year} - Successfully processed {len(processed_data)} records\")\n",
        "            else:\n",
        "                failed_years.append(year)\n",
        "                print(f\"‚ùå {year} - No valid data after processing\")\n",
        "        else:\n",
        "            failed_years.append(year)\n",
        "            print(f\"‚ùå {year} - No tables found on webpage\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        failed_years.append(year)\n",
        "        print(f\"‚ùå {year} - Error occurred: {str(e)[:100]}...\")\n",
        "    \n",
        "    # Add a small delay to be respectful to the server\n",
        "    if i < len(years_to_scrape):  # Don't delay after the last request\n",
        "        time.sleep(1)  # 1 second delay between requests\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(f\"üéâ Scraping completed!\")\n",
        "print(f\"‚úÖ Successful years: {len(successful_years)} - {successful_years}\")\n",
        "print(f\"‚ùå Failed years: {len(failed_years)} - {failed_years}\")\n",
        "print(f\"üìä Total dataframes collected: {len(all_data)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# STEP 5: COMBINE ALL DATA\n",
        "# =============================================================================\n",
        "\n",
        "if all_data:\n",
        "    print(\"üîó Combining all historical data...\")\n",
        "    \n",
        "    # Combine all dataframes into one\n",
        "    combined_df = pd.concat(all_data, ignore_index=True)\n",
        "    \n",
        "    print(f\"‚úÖ Successfully combined {len(all_data)} dataframes\")\n",
        "    print(f\"üìä Combined data shape: {combined_df.shape} (rows √ó columns)\")\n",
        "    print(f\"üìã Columns: {list(combined_df.columns)}\")\n",
        "    \n",
        "    # Display basic statistics\n",
        "    print(f\"\\nüìà COMBINED DATA STATISTICS:\")\n",
        "    print(f\"   üéØ Total lottery draws: {len(combined_df):,}\")\n",
        "    \n",
        "    if 'Draw Date' in combined_df.columns:\n",
        "        print(f\"   üìÖ Date range: {combined_df['Draw Date'].min()} to {combined_df['Draw Date'].max()}\")\n",
        "        print(f\"   üìä Data spans multiple years (1993-2025) as indicated by date range\")\n",
        "    \n",
        "    # Show sample of combined data\n",
        "    print(f\"\\nüëÄ Sample of combined data (first 5 rows):\")\n",
        "    print(combined_df.head())\n",
        "    \n",
        "    print(f\"\\nüëÄ Sample of combined data (last 5 rows):\")\n",
        "    print(combined_df.tail())\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No data to combine!\")\n",
        "    combined_df = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# STEP 6: SAVE DATA TO CSV FILE\n",
        "# =============================================================================\n",
        "\n",
        "if combined_df is not None:\n",
        "    print(\"üíæ Saving combined historical data to CSV file...\")\n",
        "    \n",
        "    # Define output filename\n",
        "    output_file = 'all.csv'\n",
        "    \n",
        "    try:\n",
        "        # Save to CSV file\n",
        "        combined_df.to_csv(output_file, index=False)\n",
        "        \n",
        "        print(f\"‚úÖ Successfully saved data to '{output_file}'\")\n",
        "        print(f\"üìÅ File size: {len(combined_df):,} rows √ó {len(combined_df.columns)} columns\")\n",
        "        \n",
        "        # Display data types\n",
        "        print(f\"\\nüìä Data types:\")\n",
        "        print(combined_df.dtypes)\n",
        "        \n",
        "        # Final summary\n",
        "        print(f\"\\nüéâ HISTORICAL DATA SCRAPING COMPLETED SUCCESSFULLY!\")\n",
        "        print(f\"üìö The complete dataset ({len(combined_df):,} records) is now ready for analysis!\")\n",
        "        print(f\"üïê Completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error saving file: {e}\")\n",
        "        \n",
        "else:\n",
        "    print(\"‚ùå Cannot save data - no combined data available\")\n",
        "    print(\"üí° Check the scraping results above for any issues\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# STEP 7: DATA QUALITY CHECK AND SUMMARY\n",
        "# =============================================================================\n",
        "\n",
        "if combined_df is not None:\n",
        "    print(\"üîç Performing data quality checks...\")\n",
        "    \n",
        "    # Check for missing values\n",
        "    print(f\"\\nüìä Missing values per column:\")\n",
        "    missing_values = combined_df.isnull().sum()\n",
        "    for col, missing in missing_values.items():\n",
        "        if missing > 0:\n",
        "            print(f\"   {col}: {missing:,} missing values\")\n",
        "    \n",
        "    # Check for duplicate rows\n",
        "    duplicates = combined_df.duplicated().sum()\n",
        "    print(f\"\\nüîÑ Duplicate rows: {duplicates:,}\")\n",
        "    \n",
        "    # Check number columns for valid ranges (1-49 for Mark Six)\n",
        "    number_columns = [col for col in combined_df.columns if col.startswith('num')]\n",
        "    if number_columns:\n",
        "        print(f\"\\nüé≤ Number column analysis:\")\n",
        "        for col in number_columns:\n",
        "            # Convert to numeric, errors='coerce' will turn invalid values to NaN\n",
        "            numeric_values = pd.to_numeric(combined_df[col], errors='coerce')\n",
        "            valid_numbers = numeric_values.dropna()\n",
        "            \n",
        "            if len(valid_numbers) > 0:\n",
        "                min_val = valid_numbers.min()\n",
        "                max_val = valid_numbers.max()\n",
        "                print(f\"   {col}: Range {min_val}-{max_val}, Valid values: {len(valid_numbers):,}\")\n",
        "            else:\n",
        "                print(f\"   {col}: No valid numeric values\")\n",
        "    \n",
        "    # Date-based analysis (since Year column is removed)\n",
        "    if 'Draw Date' in combined_df.columns:\n",
        "        print(f\"\\nüìÖ Date-based analysis:\")\n",
        "        print(f\"   Data spans from {combined_df['Draw Date'].min()} to {combined_df['Draw Date'].max()}\")\n",
        "        print(f\"   Total unique dates: {combined_df['Draw Date'].nunique()}\")\n",
        "    \n",
        "    print(f\"\\n‚úÖ Data quality check completed!\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå Cannot perform quality check - no data available\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# END OF HISTORICAL SCRAPING NOTEBOOK\n",
        "# =============================================================================\n",
        "# This notebook demonstrates comprehensive historical data scraping\n",
        "# for Hong Kong Mark Six lottery results from 1993 to 2025.\n",
        "# \n",
        "# Key features:\n",
        "# - Scrapes 33 years of lottery data\n",
        "# - Handles errors gracefully with retry logic\n",
        "# - Combines all data into a single CSV file\n",
        "# - Includes data quality checks\n",
        "# - Educational step-by-step approach\n",
        "#\n",
        "# Output: all.csv (complete historical dataset)\n",
        "# =============================================================================\n",
        "\n",
        "print(\"üìö Historical Mark Six Lottery Data Scraper\")\n",
        "print(\"üéØ Successfully scraped data from 1993 to 2025\")\n",
        "print(\"üìÅ Output file: all.csv\")\n",
        "print(\"üî¨ Ready for analysis, machine learning, or further processing!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
